{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de sentimiento de secuencias en Keras usando RNNs\n",
    "    \n",
    "   Vamos a ver un ejemplo de **secuencia a valor** de aplicación de LSTMs. Este consiste en clasificar las críticas de IMDB.\n",
    "   \n",
    "\n",
    "    \n",
    "### Cargamos el dataset imdb\",\n",
    "    \n",
    "`Keras` incorpora una utilidad de acceso a este data-set https://keras.io/datasets/#imdb-movie-reviews-sentiment-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras as kr\n",
    "import tensorflow as tf\n",
    "# tf.python.control_flow_ops = tf #esta línea evita un conflicto entre Kera y Tensorflow\n",
    "\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, GRU\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.9'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kr.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        ?imdb.load_data()\n",
    "\n",
    "        imdb.load_data(path='imdb_full.pkl', nb_words=None, skip_top=0, maxlen=None, seed=113, start_char=1, oov_char=2, index_from=3)\n",
    "        Docstring:\n",
    "        Loads IMDB dataset.\n",
    "\n",
    "        # Arguments\n",
    "            path: where to store the data (in `/.keras/dataset`)\n",
    "            nb_words: max number of words to include. Words are ranked\n",
    "                by how often they occur (in the training set) and only\n",
    "                the most frequent words are kept\n",
    "            skip_top: skip the top N most frequently occuring words\n",
    "                (which may not be informative).\n",
    "            maxlen: truncate sequences after this length.\n",
    "            seed: random seed for sample shuffling.\n",
    "            start_char: The start of a sequence will be marked with this character.\n",
    "                Set to 1 because 0 is usually the padding character.\n",
    "            oov_char: words that were cut out because of the `nb_words`\n",
    "                or `skip_top` limit will be replaced with this character.\n",
    "            index_from: index actual words with this index and higher.\n",
    "\n",
    "        Note that the 'out of vocabulary' character is only used for\n",
    "        words that were present in the training set but are not included\n",
    "        because they're not making the `nb_words` cut here.\n",
    "        Words that were not seen in the trining set but are in the test set\n",
    "        have simply been skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/infinitemonkeys/anaconda3/lib/python3.5/site-packages/keras/datasets/imdb.py:45: UserWarning: The `nb_words` argument in `load_data` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `load_data` '\n"
     ]
    }
   ],
   "source": [
    "top_words = 5000\n",
    "max_len=500\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(path=\"imdb_full.pkl\",\n",
    "                                                         nb_words=top_words, #usamos 1000 palabras más frecuentes\",\n",
    "                                                          skip_top=0,\n",
    "                                                          maxlen=max_len, #tomamos secuencias de hasta 500 palabras\",\n",
    "                                                          seed=113,\n",
    "                                                          start_char=1,\n",
    "                                                          oov_char=2,\n",
    "                                                         index_from=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elegimos usar las 1000 palabras más frecuentes y secuencias de longitud 500.\n",
    "\n",
    "X_train,X_test son arrays formados por listas de longitud hasta 500, hay 25000 listas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "499"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_crit=np.array([len(X_train[k]) for k in range(X_train.shape[0])])\n",
    "np.max(long_crit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6144cc8d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "sns.distplot(long_crit);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando el preprocesamiento de keras completamos las secuencias con valores irrelevantes introducidos previamente  (0 es el símbolo elegido), hasta que todas tienen longitud 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = sequence.pad_sequences(X_train, padding='pre',maxlen=max_len)\n",
    "X_test = sequence.pad_sequences(X_test, padding='pre',maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    1, 4078,    2,    9,  448,\n",
       "        725,    4,    2,  241,    2,  241,   38,  111,    2,  500,   40,\n",
       "         91,  374,  500,  679,  102,   13,   62,  135,    4, 2159,   92,\n",
       "          2,   83,    6,  275, 3449,   66,   73,    5,   15,  271,   18,\n",
       "         14,   31,   99, 2149,   10,   10,  225,    6,  184,  196,    2,\n",
       "         63, 2568,    5,  732,    4,  863,   18,    4,   65,    5,    4,\n",
       "       1397, 1111,   23,   63,    6,  564, 4892,    2,    5,   27,  476,\n",
       "        577,    2,    2,    2,    5,  492,    2,    2,    2,  216,    8,\n",
       "        847,   83,    4,    2,   92,  168,   32,   99, 2575,    5,  515,\n",
       "        195,  481, 2017,    9,  348,   44,    4,    2,   23,    4, 1111,\n",
       "          8,  789,    2,  280,    4,    2,  517,    2,   10,   10, 1958,\n",
       "          5, 1364,  183,  380,    8,  140,    2,    5,  263,    2,  140,\n",
       "         23,    6, 1973, 3318,  187,    4, 3450,    8, 1974,  618,   51,\n",
       "          9, 1448,   23,   14,    2, 1111,   19,   94,  680,    2,   21,\n",
       "         11,  882,   25,   80,   24, 1414,   19,  803,  170,   23,   17,\n",
       "          2,    5, 2447, 2953,   79, 1376,   11,    8,    2,    4,  114,\n",
       "         60,   53,   51,   16,   66, 3742,   12,   83,    4,    2,    7,\n",
       "         78,  212,   26,   94,    2, 1815, 2611,   46,    7,    4,    2,\n",
       "        388,   63,   43, 2266,    2,    2,   33,   94, 2099, 3002,  366,\n",
       "         45, 1852,   76,  303,   45,   31,  155,  269,    8,  216,   56,\n",
       "          5,  984,  142, 1393,   21,  160,  155,  399,   12, 4521,    5,\n",
       "         19,    2, 2380,   10,   10,  466,   12,    2,   11,  467, 1552,\n",
       "        234,   13,  104,   45,    6,  189,   20,    2,    8,   28,   15,\n",
       "         17,    6,    2,    2,   12,  408,   15,  220,  107,  534,  235,\n",
       "         19,   94,  550,    2,    8,  376,   51,   12,  494,    8,  183,\n",
       "        895,    8, 1261,   56, 1841,    4,  236,  891,  234,   21,   45,\n",
       "          6,  356,  420,    7,   99,  117,   99,  522,   10,   10,   51,\n",
       "       3220,    4,   20,    9,   89,   12, 1443,    2,    5,   94, 3411,\n",
       "         33,    4,  130,  174,   14,    9,    6, 1141, 2701,  343,    8,\n",
       "        353,    5,    2,    6, 1573,  606,  189,   20,   83,  142,    6,\n",
       "        117,  227, 1727,   11,    4,  440,    7,    2,   35,  311,   12,\n",
       "        679,   46,  247,    2,   21,  889,    6,   78,    2,   17,  490,\n",
       "        235, 4563,  643,   50,   26,  107,  771,    6, 1009,   80,   97,\n",
       "         25,  235,   12,  345,    2,    4,   20,    8,    6,  906,  651,\n",
       "         42, 1568,   25,   19,   15,    2,  547,  472, 4078,    2,    2,\n",
       "         53,    8,    4, 1569,   10,   10,    4, 1907, 1698,   80,   30,\n",
       "         94,  627,   19,   94,  361,    7,  641, 3788,    5,    2,   21,\n",
       "         13,   80,   30,   15, 3759,   45,  131,   24,  290,    4,   58,\n",
       "         38,  128,    8,  798,   14], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicamos LSTM\n",
    "\n",
    "Vamos a generar ahora una LSTM con dos capas:\n",
    "   - `Embedding` - Es la capa que transforma los índices enteros en vectores densos de longitud 32 para que las capas posteriores puedan procesarlos.\n",
    "   - `LSTM` - Es la capa que trabaja en la clasificación. Ponemos 200 neuronas.\n",
    "   - Una única neurona de salida con un sigmoide ya que estamos ante una clasificación 0-1 (crítica positiva, crítica negativa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_vector_length=32\n",
    "\n",
    "def modelLSTM(n_lstm):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(top_words, embedding_vector_length, input_length=max_len))\n",
    "    model.add(LSTM(n_lstm))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn=modelLSTM(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 213,301\n",
      "Trainable params: 213,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/infinitemonkeys/anaconda3/lib/python3.5/site-packages/keras/models.py:874: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 20947 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 156s 6ms/step - loss: 0.4467 - acc: 0.7904 - val_loss: 0.3506 - val_acc: 0.8508\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 155s 6ms/step - loss: 0.3162 - acc: 0.8694 - val_loss: 0.3167 - val_acc: 0.8714\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 157s 6ms/step - loss: 0.2475 - acc: 0.9032 - val_loss: 0.3024 - val_acc: 0.8722\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6113f816a0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#entrenamos el modelo\n",
    "rnn.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=3, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20947/20947 [==============================] - 47s 2ms/step\n",
      "Accuracy: 87.22%\n"
     ]
    }
   ],
   "source": [
    "scores = rnn.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la primera prueba usando LSTM nos ubicamos en una precisión del 86.67% en el dataset, del artículo https://cs224d.stanford.edu/reports/HongJames.pdf sabemos que precisiones desarrolladas son\n",
    "\n",
    "<img src='imdbresults.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modelGRU(n_gru):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(top_words, embedding_vector_length, input_length=max_len))\n",
    "    model.add(GRU(n_gru))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_4 (Embedding)          (None, 500, 32)       160000      embedding_input_4[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "gru_1 (GRU)                      (None, 100)           39900       embedding_4[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 1)             101         gru_1[0][0]                      \n",
      "====================================================================================================\n",
      "Total params: 200,001\n",
      "Trainable params: 200,001\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnnGRU=modelGRU(100)\n",
    "rnnGRU.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 20947 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 157s - loss: 0.4505 - acc: 0.7787 - val_loss: 0.3389 - val_acc: 0.8549\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 157s - loss: 0.2878 - acc: 0.8832 - val_loss: 0.3074 - val_acc: 0.8739\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 156s - loss: 0.2503 - acc: 0.9020 - val_loss: 0.3231 - val_acc: 0.8775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbf09c29be0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#entrenamos el modelo\n",
    "rnnGRU.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=3, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rnnGRU' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-a4d6b7df1c94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnnGRU\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy: %.2f%%\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rnnGRU' is not defined"
     ]
    }
   ],
   "source": [
    "scores = rnnGRU.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU regularizado con dropout\n",
    "\n",
    "Usando celdas GRU hemos tardado menos y hemos mejorado ligeramente la precisión. Vamos a probar una versión regularizada del algoritmo con más epochs y neuronas para observar si mejora la precisión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modelGRUdrop(n_gru,p_drop_W,p_drop_U):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(top_words, embedding_vector_length, input_length=max_len))\n",
    "    model.add(GRU(n_gru,dropout_W=p_drop_W,dropout_U=p_drop_U))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnnGRUdrop=modelGRUdrop(200,0.1,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 20947 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 174s - loss: 0.5104 - acc: 0.7394 - val_loss: 0.4096 - val_acc: 0.8169\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 173s - loss: 0.3730 - acc: 0.8413 - val_loss: 0.3544 - val_acc: 0.8564\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 173s - loss: 0.2897 - acc: 0.8849 - val_loss: 0.2885 - val_acc: 0.8845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbf0833f9b0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#entrenamos el modelo\n",
    "rnnGRUdrop.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=3, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20947/20947 [==============================] - 68s    \n",
      "Accuracy: 88.45%\n"
     ]
    }
   ],
   "source": [
    "scores = rnnGRUdrop.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La regularización ha mejorado la precisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modelGRUdrop2(n_gru,n_dense,p_drop_W,p_drop_U):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(top_words, embedding_vector_length, input_length=max_len))\n",
    "    model.add(GRU(n_gru,dropout_W=p_drop_W,dropout_U=p_drop_U))\n",
    "    model.add(Dense(n_dense, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnnGRUdrop = modelGRUdrop2(200,200,0.1,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 20947 samples\n",
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 164s - loss: 0.5014 - acc: 0.7514 - val_loss: 0.3890 - val_acc: 0.8248\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 162s - loss: 0.3597 - acc: 0.8442 - val_loss: 0.4549 - val_acc: 0.7809\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 161s - loss: 0.2682 - acc: 0.8923 - val_loss: 0.3090 - val_acc: 0.8704\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 161s - loss: 0.2017 - acc: 0.9208 - val_loss: 0.2826 - val_acc: 0.8854\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 161s - loss: 0.1548 - acc: 0.9405 - val_loss: 0.3029 - val_acc: 0.8906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f79b0ec1198>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnnGRUdrop.fit(X_train, y_train, validation_data=(X_test, y_test), \n",
    "               nb_epoch=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20947/20947 [==============================] - 62s    \n",
      "Accuracy: 89.06%\n"
     ]
    }
   ],
   "source": [
    "scores = rnnGRUdrop.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "117px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
