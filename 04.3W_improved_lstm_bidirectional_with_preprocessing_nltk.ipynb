{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9d2dbdb3-6c74-4f96-9865-2951dfd653ce",
    "_uuid": "bb41ad86b25fecf332927b0c8f55dd710101e33f"
   },
   "source": [
    "# Improved LSTM baseline\n",
    "\n",
    "This kernel is a somewhat improved version of [Keras - Bidirectional LSTM baseline](https://www.kaggle.com/CVxTz/keras-bidirectional-lstm-baseline-lb-0-051) along with some additional documentation of the steps. (NB: this notebook has been re-run on the new test set.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T03:00:40.170251Z",
     "start_time": "2018-02-18T03:00:40.156673Z"
    },
    "_cell_guid": "2f9b7a76-8625-443d-811f-8f49781aef81",
    "_uuid": "598f965bc881cfe6605d92903b758778d400fa8b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os, re, csv, codecs, time, numpy as np, pandas as pd\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from kaggletoxicity.keras_utils import KaggleToxicityValMetric\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "import constants as ct\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T03:36:33.596861Z",
     "start_time": "2018-02-18T03:36:33.590528Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the initial block is copied from creating_word_vectors_with_word2vec.ipynb\n",
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "from bokeh.io import output_notebook, output_file\n",
    "from bokeh.plotting import show, figure\n",
    "\n",
    "# new!\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "from gensim.models.phrases import Phraser, Phrases\n",
    "from keras.preprocessing.text import one_hot\n",
    "from gensim.models import FastText\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T02:44:08.366935Z",
     "start_time": "2018-02-18T02:44:08.362189Z"
    },
    "_cell_guid": "66a6b5fd-93f0-4f95-ad62-3253815059ba",
    "_uuid": "729b0f0c2a02c678631b8c072d62ff46146a82ef",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA_FILE = os.path.join(ct.DATA_FOLDER, 'train.csv')\n",
    "TEST_DATA_FILE = os.path.join(ct.DATA_FOLDER, 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T03:03:36.011437Z",
     "start_time": "2018-02-18T03:03:34.859662Z"
    },
    "_cell_guid": "ac2e165b-1f6e-4e69-8acf-5ad7674fafc3",
    "_uuid": "8ab6dad952c65e9afcf16e43c4043179ef288780",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(TRAIN_DATA_FILE)\n",
    "test = pd.read_csv(TEST_DATA_FILE)\n",
    "\n",
    "list_sentences_train = train[\"comment_text\"].fillna(\"_na_\").values.tolist()\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "y = train[list_classes].values.tolist()\n",
    "list_sentences_test = test[\"comment_text\"].fillna(\"_na_\").values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T03:03:38.185445Z",
     "start_time": "2018-02-18T03:03:38.180846Z"
    },
    "_cell_guid": "2807a0a5-2220-4af6-92d6-4a7100307de2",
    "_uuid": "d365d5f8d9292bb9bf57d21d6186f8b619cbe8c3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed_size = 50 # how big is each word vector\n",
    "max_features = 20000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = 500 # max number of words in a comment to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T03:03:39.001038Z",
     "start_time": "2018-02-18T03:03:38.995381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/infinitemonkeys/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/infinitemonkeys/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T03:03:39.339665Z",
     "start_time": "2018-02-18T03:03:39.335545Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STOPWORDS = stopwords.words('english') + list(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T03:31:08.812137Z",
     "start_time": "2018-02-18T03:31:08.805435Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenized_text_preprocesser(text, stem=False, stopwords=True):\n",
    "    \n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    if stem and stopwords:\n",
    "        text = [stemmer.stem(w.lower()) for w in text if w not in STOPWORDS]\n",
    "    elif stem and (not stopwords):\n",
    "        text = [stemmer.stem(w.lower()) for w in text]\n",
    "    elif (not stem) and stopwords:\n",
    "        text = [w.lower() for w in text if w not in STOPWORDS]\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T03:10:08.121064Z",
     "start_time": "2018-02-18T03:08:44.538248Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159571/159571 [01:23<00:00, 1912.36it/s]\n"
     ]
    }
   ],
   "source": [
    "list_sentences_train_tokenized = []\n",
    "\n",
    "for text in tqdm(list_sentences_train):\n",
    "    list_sentences_train_tokenized.append(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T03:11:23.173334Z",
     "start_time": "2018-02-18T03:10:08.122194Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153164/153164 [01:15<00:00, 2040.88it/s]\n"
     ]
    }
   ],
   "source": [
    "list_sentences_test_tokenized = []\n",
    "\n",
    "for text in tqdm(list_sentences_test):\n",
    "    list_sentences_test_tokenized.append(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T03:13:01.300223Z",
     "start_time": "2018-02-18T03:12:49.138789Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159571/159571 [00:12<00:00, 13127.61it/s]\n"
     ]
    }
   ],
   "source": [
    "lower_sents_train = []\n",
    "for s in tqdm(list_sentences_train_tokenized):\n",
    "    lower_sents_train.append([w.lower() for w in s if w not in list(string.punctuation)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T03:13:26.093042Z",
     "start_time": "2018-02-18T03:13:15.972744Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153164/153164 [00:10<00:00, 15143.35it/s]\n"
     ]
    }
   ],
   "source": [
    "lower_sents_test = []\n",
    "for s in tqdm(list_sentences_test_tokenized):\n",
    "    lower_sents_test.append([w.lower() for w in s if w not in list(string.punctuation)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T03:15:50.230058Z",
     "start_time": "2018-02-18T03:14:32.400854Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lower_bigram_train = Phraser(Phrases(lower_sents_train, min_count=32, threshold=64))\n",
    "lower_bigram_test = Phraser(Phrases(lower_sents_test, min_count=32, threshold=64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T03:16:22.215253Z",
     "start_time": "2018-02-18T03:15:54.042955Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159571/159571 [00:28<00:00, 5665.06it/s]\n"
     ]
    }
   ],
   "source": [
    "clean_sents_train = []\n",
    "for s in tqdm(lower_sents_train):\n",
    "    clean_sents_train.append(lower_bigram_train[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T03:16:45.950153Z",
     "start_time": "2018-02-18T03:16:22.216313Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153164/153164 [00:23<00:00, 6454.31it/s]\n"
     ]
    }
   ],
   "source": [
    "clean_sents_test = []\n",
    "for s in tqdm(lower_sents_test):\n",
    "    clean_sents_test.append(lower_bigram_test[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T03:19:12.314496Z",
     "start_time": "2018-02-18T03:19:12.309202Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Explanation',\n",
       " 'Why',\n",
       " 'the',\n",
       " 'edits',\n",
       " 'made',\n",
       " 'under',\n",
       " 'my',\n",
       " 'username',\n",
       " 'Hardcore',\n",
       " 'Metallica',\n",
       " 'Fan',\n",
       " 'were',\n",
       " 'reverted',\n",
       " '?',\n",
       " 'They',\n",
       " 'were',\n",
       " \"n't\",\n",
       " 'vandalisms',\n",
       " ',',\n",
       " 'just',\n",
       " 'closure',\n",
       " 'on',\n",
       " 'some',\n",
       " 'GAs',\n",
       " 'after',\n",
       " 'I',\n",
       " 'voted',\n",
       " 'at',\n",
       " 'New',\n",
       " 'York',\n",
       " 'Dolls',\n",
       " 'FAC',\n",
       " '.',\n",
       " 'And',\n",
       " 'please',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'remove',\n",
       " 'the',\n",
       " 'template',\n",
       " 'from',\n",
       " 'the',\n",
       " 'talk',\n",
       " 'page',\n",
       " 'since',\n",
       " 'I',\n",
       " \"'m\",\n",
       " 'retired',\n",
       " 'now.89.205.38.27']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_sentences_train_tokenized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T03:18:53.202747Z",
     "start_time": "2018-02-18T03:18:53.197550Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['explanation',\n",
       " 'why',\n",
       " 'the',\n",
       " 'edits',\n",
       " 'made',\n",
       " 'under',\n",
       " 'my',\n",
       " 'username',\n",
       " 'hardcore',\n",
       " 'metallica',\n",
       " 'fan',\n",
       " 'were',\n",
       " 'reverted',\n",
       " 'they',\n",
       " 'were',\n",
       " \"n't\",\n",
       " 'vandalisms',\n",
       " 'just',\n",
       " 'closure',\n",
       " 'on',\n",
       " 'some',\n",
       " 'gas',\n",
       " 'after',\n",
       " 'i',\n",
       " 'voted',\n",
       " 'at',\n",
       " 'new_york',\n",
       " 'dolls',\n",
       " 'fac',\n",
       " 'and',\n",
       " 'please',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'remove',\n",
       " 'the',\n",
       " 'template',\n",
       " 'from',\n",
       " 'the',\n",
       " 'talk',\n",
       " 'page',\n",
       " 'since',\n",
       " 'i',\n",
       " \"'m\",\n",
       " 'retired',\n",
       " 'now.89.205.38.27']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_sents_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T03:32:05.789015Z",
     "start_time": "2018-02-18T03:31:23.479058Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_sents_train_stop = [tokenized_text_preprocesser(text, stem=False, stopwords=True) for text in clean_sents_train]\n",
    "clean_sents_test_stop = [tokenized_text_preprocesser(text, stem=False, stopwords=True) for text in clean_sents_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T03:34:11.393748Z",
     "start_time": "2018-02-18T03:34:11.389437Z"
    }
   },
   "outputs": [],
   "source": [
    "# clean_sents_train_stop_stem = [tokenized_text_preprocesser(text, stem=True, stopwords=True) for text in clean_sents_train]\n",
    "# clean_sents_test_stop_stem = [tokenized_text_preprocesser(text, stem=True, stopwords=True) for text in clean_sents_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T03:36:10.606536Z",
     "start_time": "2018-02-18T03:36:10.600513Z"
    }
   },
   "outputs": [],
   "source": [
    "# clean_sents_train_stem = [tokenized_text_preprocesser(text, stem=True, stopwords=False) for text in clean_sents_train]\n",
    "# clean_sents_test_stem = [tokenized_text_preprocesser(text, stem=True, stopwords=False) for text in clean_sents_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T03:36:18.259926Z",
     "start_time": "2018-02-18T03:36:18.045733Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame({'comment_text': clean_sents_train}, index=train.index)\n",
    "test_df = pd.DataFrame({'comment_text': clean_sents_test}, index=test.index)\n",
    "\n",
    "train_stop_df = pd.DataFrame({'comment_text': clean_sents_train_stop}, index=train.index)\n",
    "test_stop_df = pd.DataFrame({'comment_text': clean_sents_test_stop}, index=test.index)\n",
    "\n",
    "# train_stop_stem_df = pd.DataFrame({'comment_text': clean_sents_train_stop_stem}, index=train.index)\n",
    "# test_stop_stem_df = pd.DataFrame({'comment_text': clean_sents_test_stop_stem}, index=test.index)\n",
    "\n",
    "# train_stem_df = pd.DataFrame({'comment_text': clean_sents_train_stem}, index=train.index)\n",
    "# test_stem_df = pd.DataFrame({'comment_text': clean_sents_test_stem}, index=test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T03:40:58.144269Z",
     "start_time": "2018-02-18T03:40:51.851188Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/infinitemonkeys/anaconda3/lib/python3.5/site-packages/pandas/core/generic.py:1471: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['comment_text']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# train_df.to_csv(os.path.join(ct.DATA_FOLDER, 'processed_train_df.csv' ), index=False)\n",
    "train_df.to_hdf(ct.STORE_PATH, 'processed_train_df')\n",
    "test_df.to_hdf(ct.STORE_PATH, 'processed_testn_df')\n",
    "train_stop_df.to_hdf(ct.STORE_PATH, 'processed_train_stop_df')\n",
    "test_stop_df.to_hdf(ct.STORE_PATH, 'processed_test_stop_df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generamos los *embeddings*\n",
    "https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/FastText_Tutorial.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T03:51:06.556718Z",
     "start_time": "2018-02-18T03:42:21.204956Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb = FastText(clean_sents_train + clean_sents_test, size=64,\n",
    "               window=10, min_count=10, workers=8, sg=1, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T03:57:40.571380Z",
     "start_time": "2018-02-18T03:51:06.557666Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_stop = FastText(clean_sents_train_stop + clean_sents_test_stop, size=64, window=10, min_count=10, workers=8,sg=1, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T03:58:00.959297Z",
     "start_time": "2018-02-18T03:57:57.818762Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb.save(os.path.join(ct.DATA_TOOLS_FOLDER, 'emb.w2v'))\n",
    "emb_stop.save(os.path.join(ct.DATA_TOOLS_FOLDER, 'emb_stop.w2v'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://codekansas.github.io/blog/2016/gensim.html\n",
    "- http://adventuresinmachinelearning.com/gensim-word2vec-tutorial/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T04:08:51.491990Z",
     "start_time": "2018-02-18T04:08:51.486383Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "from keras.engine import Input\n",
    "\n",
    "def word2vec_embedding_layer(embeddings_path):\n",
    "    weights = np.load(open(embeddings_path, 'rb'))\n",
    "    layer = Embedding(input_dim=weights.shape[0], output_dim=weights.shape[1], weights=[weights])\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T04:10:45.262963Z",
     "start_time": "2018-02-18T04:10:45.239002Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_layer = word2vec_embedding_layer(os.path.join(ct.DATA_TOOLS_FOLDER, 'emb.w2v.wv.vectors_ngrams.npy'))\n",
    "embedding_stop_layer = word2vec_embedding_layer(os.path.join(ct.DATA_TOOLS_FOLDER, 'emb_stop.w2v.wv.vectors_ngrams.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "98f2b724-7d97-4da8-8b22-52164463a942",
    "_uuid": "b62d39216c8d00b3e6b78b825212fd190757dff9"
   },
   "source": [
    "Set some basic config parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b3a8d783-95c2-4819-9897-1320e3295183",
    "_uuid": "4dd8a02e7ef983f10ec9315721c6dda2958024af"
   },
   "source": [
    "Read in our data and replace missing values:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "54a7a34e-6549-45f7-ada2-2173ff2ce5ea",
    "_uuid": "e8810c303980f41dbe0543e1c15d35acbdd8428f"
   },
   "source": [
    "Standard keras preprocessing, to turn each comment into a list of word indexes of equal length (with truncation or padding as needed)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T04:51:33.538205Z",
     "start_time": "2018-02-18T04:51:33.532821Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_data_to_index(string_data, wv):\n",
    "    index_data = []\n",
    "    for word in string_data:\n",
    "        if word in wv.vocab:\n",
    "            index_data.append(wv.vocab[word].index)\n",
    "    return index_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T04:52:06.512653Z",
     "start_time": "2018-02-18T04:51:58.518067Z"
    },
    "_cell_guid": "79afc0e9-b5f0-42a2-9257-a72458e91dbb",
    "_uuid": "c292c2830522bfe59d281ecac19f3a9415c07155"
   },
   "outputs": [],
   "source": [
    "X_t = pad_sequences([convert_data_to_index(w, emb.wv) for w in clean_sents_train], maxlen=maxlen)\n",
    "X_te = pad_sequences([convert_data_to_index(w, emb.wv) for w in clean_sents_test], maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T04:52:27.136477Z",
     "start_time": "2018-02-18T04:52:25.385154Z"
    },
    "_cell_guid": "0d4cb718-7f9a-4eab-acda-8f55b4712439",
    "_uuid": "dc51af0bd046e1eccc29111a8e2d77bdf7c60d28",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = Input(shape=(maxlen,))\n",
    "x = embedding_layer(inp)\n",
    "x = Bidirectional(LSTM(50, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dense(50, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(6, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4a624b55-3720-42bc-ad5a-7cefc76d83f6",
    "_uuid": "e2a0e9ce12e1ff5ea102665e79de23df5caf5802"
   },
   "source": [
    "Now we're ready to fit out model! Use `validation_split` when not submitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T04:52:29.065658Z",
     "start_time": "2018-02-18T04:52:29.060653Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 500)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T05:46:18.271735Z",
     "start_time": "2018-02-18T04:52:30.252062Z"
    },
    "_cell_guid": "333626f1-a838-4fea-af99-0c78f1ef5f5c",
    "_uuid": "c1558c6b2802fc632edc4510c074555a590efbd8",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 151592 samples, validate on 7979 samples\n",
      "Epoch 1/50\n",
      "151592/151592 [==============================] - 125s 826us/step - loss: 0.1799 - val_loss: 0.1164 - val_roc_auc: 0.8317\n",
      "Epoch 2/50\n",
      "151592/151592 [==============================] - 124s 820us/step - loss: 0.0999 - val_loss: 0.0749 - val_roc_auc: 0.9480\n",
      "Epoch 3/50\n",
      "151592/151592 [==============================] - 124s 821us/step - loss: 0.0669 - val_loss: 0.0570 - val_roc_auc: 0.9670\n",
      "Epoch 4/50\n",
      "151592/151592 [==============================] - 124s 821us/step - loss: 0.0546 - val_loss: 0.0531 - val_roc_auc: 0.9726\n",
      "Epoch 5/50\n",
      "151592/151592 [==============================] - 124s 819us/step - loss: 0.0502 - val_loss: 0.0510 - val_roc_auc: 0.9738\n",
      "Epoch 6/50\n",
      "151592/151592 [==============================] - 125s 823us/step - loss: 0.0484 - val_loss: 0.0506 - val_roc_auc: 0.9743\n",
      "Epoch 7/50\n",
      "151592/151592 [==============================] - 125s 823us/step - loss: 0.0470 - val_loss: 0.0499 - val_roc_auc: 0.9752\n",
      "Epoch 8/50\n",
      "151592/151592 [==============================] - 124s 816us/step - loss: 0.0457 - val_loss: 0.0505 - val_roc_auc: 0.9755\n",
      "Epoch 9/50\n",
      "151592/151592 [==============================] - 124s 818us/step - loss: 0.0447 - val_loss: 0.0498 - val_roc_auc: 0.9761\n",
      "Epoch 10/50\n",
      "151592/151592 [==============================] - 125s 823us/step - loss: 0.0439 - val_loss: 0.0495 - val_roc_auc: 0.9771\n",
      "Epoch 11/50\n",
      "151592/151592 [==============================] - 124s 817us/step - loss: 0.0430 - val_loss: 0.0493 - val_roc_auc: 0.9768\n",
      "Epoch 12/50\n",
      "151592/151592 [==============================] - 124s 820us/step - loss: 0.0424 - val_loss: 0.0494 - val_roc_auc: 0.9773\n",
      "Epoch 13/50\n",
      "151592/151592 [==============================] - 124s 820us/step - loss: 0.0418 - val_loss: 0.0492 - val_roc_auc: 0.9774\n",
      "Epoch 14/50\n",
      "151592/151592 [==============================] - 124s 817us/step - loss: 0.0413 - val_loss: 0.0490 - val_roc_auc: 0.9770\n",
      "Epoch 15/50\n",
      "151592/151592 [==============================] - 124s 816us/step - loss: 0.0411 - val_loss: 0.0492 - val_roc_auc: 0.9775\n",
      "Epoch 16/50\n",
      "151592/151592 [==============================] - 124s 815us/step - loss: 0.0406 - val_loss: 0.0489 - val_roc_auc: 0.9775\n",
      "Epoch 17/50\n",
      "151592/151592 [==============================] - 124s 816us/step - loss: 0.0402 - val_loss: 0.0495 - val_roc_auc: 0.9776\n",
      "Epoch 18/50\n",
      "151592/151592 [==============================] - 124s 819us/step - loss: 0.0401 - val_loss: 0.0491 - val_roc_auc: 0.9778\n",
      "Epoch 19/50\n",
      "151592/151592 [==============================] - 124s 817us/step - loss: 0.0399 - val_loss: 0.0493 - val_roc_auc: 0.9777\n",
      "Epoch 20/50\n",
      "151592/151592 [==============================] - 124s 815us/step - loss: 0.0397 - val_loss: 0.0494 - val_roc_auc: 0.9779\n",
      "Epoch 21/50\n",
      "151592/151592 [==============================] - 124s 817us/step - loss: 0.0395 - val_loss: 0.0491 - val_roc_auc: 0.9780\n",
      "Epoch 22/50\n",
      "151592/151592 [==============================] - 124s 818us/step - loss: 0.0392 - val_loss: 0.0489 - val_roc_auc: 0.9779\n",
      "Epoch 23/50\n",
      "151592/151592 [==============================] - 124s 817us/step - loss: 0.0391 - val_loss: 0.0491 - val_roc_auc: 0.9777\n",
      "Epoch 24/50\n",
      "151592/151592 [==============================] - 124s 818us/step - loss: 0.0388 - val_loss: 0.0494 - val_roc_auc: 0.9779\n",
      "Epoch 25/50\n",
      "151592/151592 [==============================] - 124s 819us/step - loss: 0.0387 - val_loss: 0.0496 - val_roc_auc: 0.9779\n",
      "Epoch 26/50\n",
      "151592/151592 [==============================] - 123s 814us/step - loss: 0.0386 - val_loss: 0.0493 - val_roc_auc: 0.9779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f52f240c6d8>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "epochs = 50\n",
    "val_prop = 0.05\n",
    "es_patience = 5\n",
    "rlr_patience = 2\n",
    "rlr_cooldown = 4\n",
    "\n",
    "file_path = os.path.join(ct.MODELS_FOLDER, \"weights_base_best_fast_text_emb.hdf5\")\n",
    "extraval = KaggleToxicityValMetric()\n",
    "early_stop = EarlyStopping(monitor='val_roc_auc', patience=es_patience, mode='max',  verbose=0)\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_roc_auc', verbose=0, mode='max',   save_best_only=True)\n",
    "reduce_lr = ReduceLROnPlateau( monitor='val_roc_auc', \n",
    "                              factor=0.5, \n",
    "                              patience=rlr_patience, \n",
    "                              cooldown=rlr_cooldown, \n",
    "                              min_lr=1e-4)\n",
    "\n",
    "callbacks_list = [extraval, checkpoint, early_stop, reduce_lr]\n",
    "model.fit(X_t, np.array(y), batch_size=batch_size, epochs=epochs, validation_split=val_prop, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d6fa2ace-aa92-40cf-913f-a8f5d5a4b130",
    "_uuid": "3dbaa4d0c22271b8b0dc7e58bcad89ddc607beaf"
   },
   "source": [
    "And finally, get predictions for the test set and prepare a submission CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T05:46:44.007246Z",
     "start_time": "2018-02-18T05:46:18.272769Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153164/153164 [==============================] - 26s 167us/step\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(file_path)\n",
    "y_test = model.predict([X_te], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T05:46:44.109301Z",
     "start_time": "2018-02-18T05:46:44.008398Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(os.path.join(ct.DATA_FOLDER, 'sample_submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T05:46:44.231753Z",
     "start_time": "2018-02-18T05:46:44.110479Z"
    },
    "_cell_guid": "28ce30e3-0f21-48e5-af3c-7e5512c9fbdc",
    "_uuid": "e59ad8a98ac5bb25a6bddd72718f3ed8a7fb52e0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_submission[list_classes] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T05:46:44.235475Z",
     "start_time": "2018-02-18T05:46:44.232965Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2018_02_18_06_46'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moment = time.strftime(\"%Y_%m_%d_%H_%M\")\n",
    "moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T05:46:45.700096Z",
     "start_time": "2018-02-18T05:46:44.236316Z"
    },
    "_cell_guid": "617e974a-57ee-436e-8484-0fb362306db2",
    "_uuid": "2b969bab77ab952ecd5abf2abe2596a0e23df251",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name = 'results_fasttext_%s.csv' % moment\n",
    "sample_submission.to_csv(os.path.join(ct.RESULTS_FOLDER, file_name), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T05:46:51.648552Z",
     "start_time": "2018-02-18T05:46:45.701788Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_t = pad_sequences([convert_data_to_index(w, emb_stop.wv) for w in clean_sents_train], maxlen=maxlen)\n",
    "X_te = pad_sequences([convert_data_to_index(w, emb_stop.wv) for w in clean_sents_test], maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T05:46:52.480503Z",
     "start_time": "2018-02-18T05:46:51.650075Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = Input(shape=(maxlen,))\n",
    "x = embedding_stop_layer(inp)\n",
    "x = Bidirectional(LSTM(50, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dense(50, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(6, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T06:27:25.517624Z",
     "start_time": "2018-02-18T05:46:52.481956Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 151592 samples, validate on 7979 samples\n",
      "Epoch 1/50\n",
      "151592/151592 [==============================] - 129s 854us/step - loss: 0.1687 - val_loss: 0.1161 - val_roc_auc: 0.8387\n",
      "Epoch 2/50\n",
      "151592/151592 [==============================] - 128s 843us/step - loss: 0.1009 - val_loss: 0.0728 - val_roc_auc: 0.9500\n",
      "Epoch 3/50\n",
      "151592/151592 [==============================] - 128s 841us/step - loss: 0.0629 - val_loss: 0.0565 - val_roc_auc: 0.9701\n",
      "Epoch 4/50\n",
      "151592/151592 [==============================] - 129s 851us/step - loss: 0.0527 - val_loss: 0.0538 - val_roc_auc: 0.9727\n",
      "Epoch 5/50\n",
      "151592/151592 [==============================] - 128s 844us/step - loss: 0.0488 - val_loss: 0.0528 - val_roc_auc: 0.9735\n",
      "Epoch 6/50\n",
      "151592/151592 [==============================] - 128s 843us/step - loss: 0.0471 - val_loss: 0.0530 - val_roc_auc: 0.9741\n",
      "Epoch 7/50\n",
      "151592/151592 [==============================] - 128s 847us/step - loss: 0.0458 - val_loss: 0.0525 - val_roc_auc: 0.9744\n",
      "Epoch 8/50\n",
      "151592/151592 [==============================] - 128s 845us/step - loss: 0.0446 - val_loss: 0.0528 - val_roc_auc: 0.9746\n",
      "Epoch 9/50\n",
      "151592/151592 [==============================] - 128s 845us/step - loss: 0.0438 - val_loss: 0.0524 - val_roc_auc: 0.9747\n",
      "Epoch 10/50\n",
      "151592/151592 [==============================] - 127s 839us/step - loss: 0.0428 - val_loss: 0.0524 - val_roc_auc: 0.9749\n",
      "Epoch 11/50\n",
      "151592/151592 [==============================] - 127s 840us/step - loss: 0.0416 - val_loss: 0.0524 - val_roc_auc: 0.9750\n",
      "Epoch 12/50\n",
      "151592/151592 [==============================] - 128s 846us/step - loss: 0.0413 - val_loss: 0.0528 - val_roc_auc: 0.9749\n",
      "Epoch 13/50\n",
      "151592/151592 [==============================] - 128s 841us/step - loss: 0.0410 - val_loss: 0.0529 - val_roc_auc: 0.9750\n",
      "Epoch 14/50\n",
      "151592/151592 [==============================] - 128s 841us/step - loss: 0.0405 - val_loss: 0.0531 - val_roc_auc: 0.9752\n",
      "Epoch 15/50\n",
      "151592/151592 [==============================] - 128s 843us/step - loss: 0.0403 - val_loss: 0.0532 - val_roc_auc: 0.9749\n",
      "Epoch 16/50\n",
      "151592/151592 [==============================] - 128s 842us/step - loss: 0.0400 - val_loss: 0.0531 - val_roc_auc: 0.9750\n",
      "Epoch 17/50\n",
      "151592/151592 [==============================] - 128s 842us/step - loss: 0.0395 - val_loss: 0.0535 - val_roc_auc: 0.9751\n",
      "Epoch 18/50\n",
      "151592/151592 [==============================] - 127s 838us/step - loss: 0.0395 - val_loss: 0.0534 - val_roc_auc: 0.9750\n",
      "Epoch 19/50\n",
      "151592/151592 [==============================] - 128s 846us/step - loss: 0.0392 - val_loss: 0.0538 - val_roc_auc: 0.9750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f52f5447e48>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "epochs = 50\n",
    "val_prop = 0.05\n",
    "es_patience = 5\n",
    "rlr_patience = 2\n",
    "rlr_cooldown = 4\n",
    "\n",
    "file_path = os.path.join(ct.MODELS_FOLDER, \"weights_base_best_fast_text_emb_stop.hdf5\")\n",
    "extraval = KaggleToxicityValMetric()\n",
    "early_stop = EarlyStopping(monitor='val_roc_auc', patience=es_patience, mode='max',  verbose=0)\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_roc_auc', verbose=0, mode='max',   save_best_only=True)\n",
    "reduce_lr = ReduceLROnPlateau( monitor='val_roc_auc', \n",
    "                              factor=0.5, \n",
    "                              patience=rlr_patience, \n",
    "                              cooldown=rlr_cooldown, \n",
    "                              min_lr=1e-4)\n",
    "\n",
    "callbacks_list = [extraval, checkpoint, early_stop, reduce_lr]\n",
    "model.fit(X_t, np.array(y), batch_size=batch_size, epochs=epochs, validation_split=val_prop, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T06:27:51.663988Z",
     "start_time": "2018-02-18T06:27:25.518671Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153164/153164 [==============================] - 26s 169us/step\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(file_path)\n",
    "y_test = model.predict([X_te], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T06:27:51.752657Z",
     "start_time": "2018-02-18T06:27:51.664986Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(os.path.join(ct.DATA_FOLDER, 'sample_submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T06:27:51.864038Z",
     "start_time": "2018-02-18T06:27:51.753761Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_submission[list_classes] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T06:27:51.867483Z",
     "start_time": "2018-02-18T06:27:51.865062Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2018_02_18_07_27'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moment = time.strftime(\"%Y_%m_%d_%H_%M\")\n",
    "moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T06:27:53.321752Z",
     "start_time": "2018-02-18T06:27:51.868429Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name = 'results_fasttext_stop_%s.csv' % moment\n",
    "sample_submission.to_csv(os.path.join(ct.RESULTS_FOLDER, file_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
